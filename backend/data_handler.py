import json
import os
import logging
from datetime import datetime, timedelta
import pytz
from config import Config

logger = logging.getLogger("data_handler")

class DataHandler:
    def __init__(self):
        self.data_dir = Config.DATA_DIR
        self.kyiv_tz = pytz.timezone('Europe/Kiev')
        self.create_data_dir()

    def create_data_dir(self):
        """–°—Ç–≤–æ—Ä–µ–Ω–Ω—è –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ–π –¥–ª—è –¥–∞–Ω–∏—Ö"""
        os.makedirs(self.data_dir, exist_ok=True)
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ –≤—Å—ñ –Ω–µ–æ–±—Ö—ñ–¥–Ω—ñ —Ñ–∞–π–ª–∏, —è–∫—â–æ —ó—Ö –Ω–µ–º–∞—î
        if not os.path.exists(Config.RECOMMENDATIONS_FILE):
            with open(Config.RECOMMENDATIONS_FILE, 'w', encoding='utf-8') as f:
                json.dump({
                    "last_update": None,
                    "recommendations": [],
                    "market_overview": {},
                    "timezone": "Europe/Kiev",
                    "analysis_id": None,
                    "total_recommendations": 0,
                    "next_analysis": None
                }, f, indent=2, ensure_ascii=False)
        
        if not os.path.exists(Config.HISTORY_FILE):
            with open(Config.HISTORY_FILE, 'w', encoding='utf-8') as f:
                json.dump([], f, indent=2, ensure_ascii=False)
                
        if not os.path.exists(Config.NEWS_CACHE_FILE):
            with open(Config.NEWS_CACHE_FILE, 'w', encoding='utf-8') as f:
                json.dump({
                    "last_update": None,
                    "news": [],
                    "news_count": 0,
                    "cache_expiry": None
                }, f, indent=2, ensure_ascii=False)
        
        if not os.path.exists(Config.ECONOMIC_INDICATORS_FILE):
            with open(Config.ECONOMIC_INDICATORS_FILE, 'w', encoding='utf-8') as f:
                json.dump({
                    "last_update": None,
                    "indicators": {},
                    "market_status": {}
                }, f, indent=2, ensure_ascii=False)

    def save_recommendations(self, data):
        """–ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π"""
        try:
            if not data or 'recommendations' not in data:
                logger.error("‚ö†Ô∏è –ù–µ–º–∞—î –¥–∞–Ω–∏—Ö –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è")
                return False
            
            recommendations = data.get('recommendations', [])
            
            if not recommendations:
                logger.warning("‚ö†Ô∏è –ù–µ–º–∞—î —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è")
                return False
            
            now_kyiv = Config.get_kyiv_time()
            
            # –û–Ω–æ–≤–ª—é—î–º–æ –¥–∞–Ω—ñ
            data_to_save = {
                "last_update": now_kyiv.isoformat(),
                "last_update_display": now_kyiv.strftime('%Y-%m-%d %H:%M:%S'),
                "recommendations": recommendations,
                "market_overview": data.get('market_overview', {}),
                "timezone": "Europe/Kiev (UTC+2)",
                "analysis_id": data.get('analysis_id', ''),
                "total_recommendations": len(recommendations),
                "news_count": data.get('news_count', 0),
                "language": data.get('language', 'uk'),
                "next_analysis": self._calculate_next_analysis_time()
            }
            
            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –≤ –æ—Å–Ω–æ–≤–Ω–∏–π —Ñ–∞–π–ª
            with open(Config.RECOMMENDATIONS_FILE, 'w', encoding='utf-8') as f:
                json.dump(data_to_save, f, indent=2, ensure_ascii=False, default=str)
            
            # –î–æ–¥–∞—î–º–æ –≤ —ñ—Å—Ç–æ—Ä—ñ—é
            self._add_to_history(data)
            
            # –û–Ω–æ–≤–ª—é—î–º–æ –∫–µ—à –Ω–æ–≤–∏–Ω
            if 'news_summary' in data:
                self._update_news_cache(data.get('news_data', []))
            
            logger.info(f"üíæ –ó–±–µ—Ä–µ–∂–µ–Ω–æ {len(recommendations)} —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π")
            
            # –û—á–∏—â–∞—î–º–æ —Å—Ç–∞—Ä—ñ –¥–∞–Ω—ñ –∑ —ñ—Å—Ç–æ—Ä—ñ—ó
            self._cleanup_old_history()
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π: {e}")
            import traceback
            logger.error(f"–î–µ—Ç–∞–ª—ñ: {traceback.format_exc()}")
            return False

    def _calculate_next_analysis_time(self):
        """–†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ —á–∞—Å—É –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É"""
        now_kyiv = Config.get_kyiv_time()
        analysis_hours = [8, 12, 16, 20]
        
        for hour in analysis_hours:
            if now_kyiv.hour < hour:
                next_time = now_kyiv.replace(hour=hour, minute=0, second=0, microsecond=0)
                return next_time.isoformat()
        
        # –Ø–∫—â–æ –≤—Å—ñ –≥–æ–¥–∏–Ω–∏ –º–∏–Ω—É–ª–∏ —Å—å–æ–≥–æ–¥–Ω—ñ, –±–µ—Ä–µ–º–æ –ø–µ—Ä—à—É –≥–æ–¥–∏–Ω—É –∑–∞–≤—Ç—Ä–∞
        next_time = (now_kyiv + timedelta(days=1)).replace(hour=8, minute=0, second=0, microsecond=0)
        return next_time.isoformat()

    def _add_to_history(self, data):
        """–î–æ–¥–∞–≤–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö –¥–æ —ñ—Å—Ç–æ—Ä—ñ—ó"""
        try:
            history = []
            if os.path.exists(Config.HISTORY_FILE):
                with open(Config.HISTORY_FILE, 'r', encoding='utf-8') as f:
                    history = json.load(f)
            
            # –°—Ç–≤–æ—Ä—é—î–º–æ –∑–∞–ø–∏—Å —ñ—Å—Ç–æ—Ä—ñ—ó
            history_entry = {
                'timestamp': data.get('timestamp', Config.get_kyiv_time().isoformat()),
                'analysis_id': data.get('analysis_id', ''),
                'recommendations_count': len(data.get('recommendations', [])),
                'market_overview': data.get('market_overview', {}),
                'top_recommendations': data.get('recommendations', [])[:3]
            }
            
            history.append(history_entry)
            
            # –û–±–º–µ–∂—É—î–º–æ —ñ—Å—Ç–æ—Ä—ñ—é –æ—Å—Ç–∞–Ω–Ω—ñ–º–∏ 100 –∑–∞–ø–∏—Å–∞–º–∏
            if len(history) > 100:
                history = history[-100:]
            
            with open(Config.HISTORY_FILE, 'w', encoding='utf-8') as f:
                json.dump(history, f, indent=2, ensure_ascii=False, default=str)
                
            logger.debug(f"üìö –î–æ–¥–∞–Ω–æ –∑–∞–ø–∏—Å –¥–æ —ñ—Å—Ç–æ—Ä—ñ—ó: {history_entry['analysis_id']}")
                
        except Exception as e:
            logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –¥–æ–¥–∞–≤–∞–Ω–Ω—è –≤ —ñ—Å—Ç–æ—Ä—ñ—é: {e}")

    def _update_news_cache(self, news_data):
        """–û–Ω–æ–≤–ª–µ–Ω–Ω—è –∫–µ—à—É –Ω–æ–≤–∏–Ω"""
        try:
            if not news_data:
                return
            
            cache_data = {
                'last_update': Config.get_kyiv_time().isoformat(),
                'news': news_data[:50],  # –ö–µ—à—É—î–º–æ –º–∞–∫—Å–∏–º—É–º 50 –Ω–æ–≤–∏–Ω
                'news_count': len(news_data),
                'cache_expiry': (Config.get_kyiv_time() + timedelta(hours=Config.CACHE_HOURS)).isoformat()
            }
            
            with open(Config.NEWS_CACHE_FILE, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, indent=2, ensure_ascii=False, default=str)
            
            logger.debug(f"üíæ –û–Ω–æ–≤–ª–µ–Ω–æ –∫–µ—à –Ω–æ–≤–∏–Ω: {len(news_data)} –∑–∞–ø–∏—Å—ñ–≤")
            
        except Exception as e:
            logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è –∫–µ—à—É –Ω–æ–≤–∏–Ω: {e}")

    def get_cached_news(self):
        """–û—Ç—Ä–∏–º–∞—Ç–∏ –∫–µ—à–æ–≤–∞–Ω—ñ –Ω–æ–≤–∏–Ω–∏"""
        try:
            if os.path.exists(Config.NEWS_CACHE_FILE):
                with open(Config.NEWS_CACHE_FILE, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ –∫–µ—à –Ω–µ –∑–∞—Å—Ç–∞—Ä—ñ–≤
                cache_expiry_str = data.get('cache_expiry')
                if cache_expiry_str:
                    cache_expiry = datetime.fromisoformat(cache_expiry_str)
                    if Config.get_kyiv_time() < cache_expiry:
                        return data.get('news', [])
        
        except Exception as e:
            logger.debug(f"–ü–æ–º–∏–ª–∫–∞ —á–∏—Ç–∞–Ω–Ω—è –∫–µ—à—É –Ω–æ–≤–∏–Ω: {e}")
        
        return []

    def load_recommendations(self):
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –ø–æ—Ç–æ—á–Ω–∏—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π"""
        try:
            if os.path.exists(Config.RECOMMENDATIONS_FILE):
                with open(Config.RECOMMENDATIONS_FILE, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    return data
            return {
                "last_update": None,
                "recommendations": [],
                "market_overview": {},
                "timezone": "Europe/Kiev",
                "analysis_id": None,
                "total_recommendations": 0,
                "next_analysis": None
            }
        except Exception as e:
            logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π: {e}")
            return {}

    def load_history(self, days=7):
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —ñ—Å—Ç–æ—Ä—ñ—ó –∑–∞ –æ—Å—Ç–∞–Ω–Ω—ñ –¥–Ω—ñ"""
        try:
            if os.path.exists(Config.HISTORY_FILE):
                with open(Config.HISTORY_FILE, 'r', encoding='utf-8') as f:
                    history = json.load(f)
                
                # –§—ñ–ª—å—Ç—Ä—É—î–º–æ –∑–∞ –¥–∞—Ç–æ—é
                filtered_history = []
                cutoff_date = Config.get_kyiv_time() - timedelta(days=days)
                
                for entry in history:
                    entry_date_str = entry.get('timestamp')
                    if entry_date_str:
                        try:
                            entry_date = datetime.fromisoformat(entry_date_str)
                            if entry_date.tzinfo is None:
                                entry_date = pytz.UTC.localize(entry_date)
                            
                            if entry_date >= cutoff_date:
                                filtered_history.append(entry)
                        except:
                            continue
                
                return filtered_history
        
        except Exception as e:
            logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —ñ—Å—Ç–æ—Ä—ñ—ó: {e}")
        
        return []

    def _cleanup_old_history(self):
        """–û—á–∏—â–µ–Ω–Ω—è —Å—Ç–∞—Ä–æ—ó —ñ—Å—Ç–æ—Ä—ñ—ó"""
        try:
            # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –≤—Å—é —ñ—Å—Ç–æ—Ä—ñ—é
            history = self.load_history(days=365)  # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∑–∞ —Ä—ñ–∫
            
            # –ó–∞–ª–∏—à–∞—î–º–æ —Ç—ñ–ª—å–∫–∏ –æ—Å—Ç–∞–Ω–Ω—ñ 100 –∑–∞–ø–∏—Å—ñ–≤
            if len(history) > 100:
                history = history[-100:]
                
                with open(Config.HISTORY_FILE, 'w', encoding='utf-8') as f:
                    json.dump(history, f, indent=2, ensure_ascii=False, default=str)
                
                logger.debug(f"üßπ –û—á–∏—â–µ–Ω–æ —ñ—Å—Ç–æ—Ä—ñ—é: –∑–∞–ª–∏—à–µ–Ω–æ {len(history)} –∑–∞–ø–∏—Å—ñ–≤")
                
        except Exception as e:
            logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –æ—á–∏—â–µ–Ω–Ω—è —ñ—Å—Ç–æ—Ä—ñ—ó: {e}")

    def get_statistics(self):
        """–û—Ç—Ä–∏–º–∞–Ω–Ω—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        stats = {
            'total_analyses': 0,
            'last_analysis': None,
            'avg_recommendations': 0,
            'most_recommended': [],
            'least_recommended': []
        }
        
        try:
            history = self.load_history(days=30)
            
            if history:
                stats['total_analyses'] = len(history)
                stats['last_analysis'] = history[-1].get('timestamp') if history else None
                
                # –†–∞—Ö—É—î–º–æ —Å–µ—Ä–µ–¥–Ω—é –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π
                total_recs = sum(h.get('recommendations_count', 0) for h in history)
                stats['avg_recommendations'] = round(total_recs / len(history), 1) if history else 0
                
                # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ –Ω–∞–π–±—ñ–ª—å—à —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω—ñ –∞–∫—Ç–∏–≤–∏
                asset_counts = {}
                for entry in history:
                    for rec in entry.get('top_recommendations', []):
                        asset = rec.get('asset')
                        action = rec.get('action')
                        
                        if asset and ('BUY' in action or 'STRONG_BUY' in action):
                            asset_counts[asset] = asset_counts.get(asset, 0) + 1
                
                if asset_counts:
                    sorted_assets = sorted(asset_counts.items(), key=lambda x: x[1], reverse=True)
                    stats['most_recommended'] = sorted_assets[:5]
        
        except Exception as e:
            logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –æ—Ç—Ä–∏–º–∞–Ω–Ω—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
        
        return stats
